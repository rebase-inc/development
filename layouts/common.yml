version: '2'

services:
  api:
    container_name: api
    build: 
      context: ../api
      args:
        PYPI_SERVER_HOST: '${PYPI_SERVER_HOST}'
        PYPI_SERVER_SCHEME: '${PYPI_SERVER_SCHEME}'
        PYPI_SERVER_PORT: '${PYPI_SERVER_PORT}'
    expose:
      - "5000"
    environment:
      S3_BUCKET: '${S3_BUCKET}'
      SECRET_KEY: '${SECRET_KEY}'
      GITHUB_APP_CLIENT_ID: '${GITHUB_APP_CLIENT_ID}'
      GITHUB_APP_CLIENT_SECRET: '${GITHUB_APP_CLIENT_SECRET}'
      PUBLIC_APP_URL: 'http://dev:3000'
      FLASK_LOGIN_SESSION_PROTECTION: "basic"
      REDIS_HOST: 'redis'
      RSYSLOG_HOST: 'logserver'
      RSYSLOG_PORT: 514
      DATABASE_HOST: 'database'
      API_URL_PREFIX: '/api/v1/'
      BACKEND_AWS_ACCESS_KEY_ID: '${BACKEND_AWS_ACCESS_KEY_ID}'
      BACKEND_AWS_SECRET_ACCESS_KEY: '${BACKEND_AWS_SECRET_ACCESS_KEY}'
  private_crawler:
    container_name: private_crawler
    hostname: private_crawler
    image: private_crawler
    build:
      context: ../private-crawler
      args:
        PYPI_SERVER_HOST: '${PYPI_SERVER_HOST}'
        PYPI_SERVER_SCHEME: '${PYPI_SERVER_SCHEME}'
        PYPI_SERVER_PORT: '${PYPI_SERVER_PORT}'
    environment:
      CRAWLER_USERNAME: '${CRAWLER_USERNAME}'
      CRAWLER_PASSWORD: '${CRAWLER_PASSWORD}'
      REPOS_VOLUME_SIZE_IN_MB: 500
      CLONE_SIZE_SAFETY_FACTOR: 2
    tmpfs:
     - /repos:rw,noexec,size=500m
